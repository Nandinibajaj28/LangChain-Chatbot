# ðŸ¤– LangChain Controlled AI Agent with Ollama/OpenAI & RAG

An experimental LLM-powered AI pipeline built to explore reliable, structured, and production-oriented AI systems using **LangChain**, **OpenAI**, and **Ollama**, featuring **Retrieval-Augmented Generation (RAG)** over PDFs, a **FastAPI backend**, and a **Streamlit frontend**.

This project focuses on **control, validation, and extensibility** in AI workflows â€” moving beyond free-form chatbots toward **AI agents that can safely integrate into real-world systems**.
Thus demonstrates how to combine **cloud LLMs** and **local LLMs** with vector databases for intelligent document-aware responses.


## âœ¨ Features

 ðŸ”¹ OpenAI-powered essay generation
 ðŸ”¹ Local LLM support using **Ollama (Gemma)**
- ðŸ”¹ Local embeddings using **Ollama embeddings**
- ðŸ”¹ PDF-based **RAG (Retrieval-Augmented Generation)**
- ðŸ”¹ Vector storage with **FAISS / Chroma**
- ðŸ”¹ FastAPI backend with LangServe
- ðŸ”¹ Streamlit interactive UI
- ðŸ”¹ Clean modular project structure


## ðŸ§  Tech Stack

- **Python 3.10 / 3.11**
- **LangChain**
- **Ollama (Gemma, nomic-embed-text)**
- **OpenAI API**
- **FAISS / ChromaDB**
- **Environment-based configuration**
- **FastAPI**
- **Streamlit**
- **PyPDF**



